TOPOLOGY_AGENT_DATABASE_URL=postgresql+asyncpg://inv_user:inv_pass@localhost:5432/inventory_db
TOPOLOGY_AGENT_ENV=dev
TOPOLOGY_AGENT_DEBUG=true

TOPOLOGY_AGENT_GRAPH_DB_URI=neo4j://localhost:7687
TOPOLOGY_AGENT_GRAPH_DB_USER=neo4j
TOPOLOGY_AGENT_GRAPH_DB_PASSWORD=quit2000
TOPOLOGY_AGENT_GRAPH_DB_ENCRYPTED=false

TOPOLOGY_AGENT_EMBEDDING_BACKEND=huggingface

# Use llama.cpp backend
TOPOLOGY_AGENT_LLM_BACKEND=llamacpp

# Point to your Mistral GGUF file
TOPOLOGY_AGENT_LLAMA_MODEL_PATH=/Users/syedraza/Code/VexaAI/ocr_router/src/models/mistral-7b-instruct-v0.2.Q4_K_M.gguf

# Optional tuning
TOPOLOGY_AGENT_LLAMA_N_CTX=4096
TOPOLOGY_AGENT_LLAMA_N_GPU_LAYERS=0     # 0 = CPU only, -1 = all layers on GPU
TOPOLOGY_AGENT_LLAMA_N_THREADS=4


